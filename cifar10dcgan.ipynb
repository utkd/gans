{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "_vA8knol6rGi"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Reshape\n",
    "from keras.layers import BatchNormalization, Activation, Conv2D, Conv2DTranspose\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "MZRiRjRj6xO4"
   },
   "outputs": [],
   "source": [
    "def get_generator(input_layer):\n",
    "  '''\n",
    "  Requires the input layer as input, outputs the model and the final layer\n",
    "  '''\n",
    "  \n",
    "  hid = Dense(128 * 16 * 16, activation='relu')(input_layer)    \n",
    "  hid = BatchNormalization(momentum=0.9)(hid)\n",
    "  hid = LeakyReLU(alpha=0.1)(hid)\n",
    "  hid = Reshape((16, 16, 128))(hid)\n",
    "\n",
    "  hid = Conv2D(128, kernel_size=5, strides=1,padding='same')(hid)\n",
    "  hid = BatchNormalization(momentum=0.9)(hid)    \n",
    "  #hid = Dropout(0.5)(hid)\n",
    "  hid = LeakyReLU(alpha=0.1)(hid)\n",
    "\n",
    "  hid = Conv2DTranspose(128, 4, strides=2, padding='same')(hid)\n",
    "  hid = BatchNormalization(momentum=0.9)(hid)\n",
    "  hid = LeakyReLU(alpha=0.1)(hid)\n",
    "\n",
    "  hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n",
    "  hid = BatchNormalization(momentum=0.9)(hid)\n",
    "  #hid = Dropout(0.5)(hid)\n",
    "  hid = LeakyReLU(alpha=0.1)(hid)\n",
    "\n",
    "  hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n",
    "  hid = BatchNormalization(momentum=0.9)(hid)\n",
    "  hid = LeakyReLU(alpha=0.1)(hid)\n",
    "                      \n",
    "  hid = Conv2D(3, kernel_size=5, strides=1, padding=\"same\")(hid)\n",
    "  out = Activation(\"tanh\")(hid)\n",
    "\n",
    "  model = Model(input_layer, out)\n",
    "  model.summary()\n",
    "  \n",
    "  return model, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "4yFseSJQ62d2"
   },
   "outputs": [],
   "source": [
    "def get_discriminator(input_layer):\n",
    "  '''\n",
    "  Requires the input layer as input, outputs the model and the final layer\n",
    "  '''\n",
    "\n",
    "  hid = Conv2D(128, kernel_size=3, strides=1, padding='same')(input_layer)\n",
    "  hid = BatchNormalization(momentum=0.9)(hid)\n",
    "  hid = LeakyReLU(alpha=0.1)(hid)\n",
    "\n",
    "  hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n",
    "  hid = BatchNormalization(momentum=0.9)(hid)\n",
    "  hid = LeakyReLU(alpha=0.1)(hid)\n",
    "\n",
    "  hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n",
    "  hid = BatchNormalization(momentum=0.9)(hid)\n",
    "  hid = LeakyReLU(alpha=0.1)(hid)\n",
    "\n",
    "  hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n",
    "  hid = BatchNormalization(momentum=0.9)(hid)\n",
    "  hid = LeakyReLU(alpha=0.1)(hid)\n",
    "\n",
    "  hid = Flatten()(hid)\n",
    "  hid = Dropout(0.4)(hid)\n",
    "  out = Dense(1, activation='sigmoid')(hid)\n",
    "\n",
    "  model = Model(input_layer, out)\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  return model, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "uFSdLdMv67Oq"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def generate_noise(n_samples, noise_dim):\n",
    "  X = np.random.normal(0, 1, size=(n_samples, noise_dim))\n",
    "  return X\n",
    "\n",
    "def show_imgs(batchidx):\n",
    "  noise = generate_noise(9, 100)\n",
    "  gen_imgs = generator.predict(noise)\n",
    "\n",
    "  fig, axs = plt.subplots(3, 3)\n",
    "  count = 0\n",
    "  for i in range(3):\n",
    "    for j in range(3):\n",
    "      # Dont scale the images back, let keras handle it\n",
    "      img = image.array_to_img(gen_imgs[count], scale=True)\n",
    "      axs[i,j].imshow(img)\n",
    "      axs[i,j].axis('off')\n",
    "      count += 1\n",
    "  plt.show()\n",
    "  plt.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Iha5HiXj7FRg"
   },
   "outputs": [],
   "source": [
    "# GAN creation\n",
    "img_input = Input(shape=(32,32,3))\n",
    "discriminator, disc_out = get_discriminator(img_input)\n",
    "discriminator.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "noise_input = Input(shape=(100,))\n",
    "generator, gen_out = get_generator(noise_input)\n",
    "\n",
    "gan_input = Input(shape=(100,))\n",
    "x = generator(gan_input)\n",
    "gan_out = discriminator(x)\n",
    "gan = Model(gan_input, gan_out)\n",
    "gan.summary()\n",
    "\n",
    "gan.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "x_C473Ji7OtQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# # Get training images\n",
    "(X_train, y_train), (X_test, _) = cifar10.load_data()\n",
    "\n",
    "# Select Cars\n",
    "X_train = X_train[y_train[:,0]==1]\n",
    "print (\"Training shape: {}\".format(X_train.shape))\n",
    "\n",
    "# Normalize data\n",
    "X_train = (X_train - 127.5) / 127.5\n",
    " \n",
    "num_batches = int(X_train.shape[0]/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "jUgkE7bW7ZNK"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 20\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "  cum_d_loss = 0.\n",
    "  cum_g_loss = 0.\n",
    "  \n",
    "  for batch_idx in range(num_batches):\n",
    "    # Get the next set of real images to be used in this iteration\n",
    "    images = X_train[batch_idx*BATCH_SIZE : (batch_idx+1)*BATCH_SIZE]\n",
    "\n",
    "    noise_data = generate_noise(BATCH_SIZE, 100)\n",
    "    generated_images = generator.predict(noise_data)\n",
    "\n",
    "    # Train on soft labels (add noise to labels as well)\n",
    "    noise_prop = 0.05 # Randomly flip 5% of labels\n",
    "    \n",
    "    # Prepare labels for real data\n",
    "    true_labels = np.zeros((BATCH_SIZE, 1)) + np.random.uniform(low=0.0, high=0.1, size=(BATCH_SIZE, 1))\n",
    "    flipped_idx = np.random.choice(np.arange(len(true_labels)), size=int(noise_prop*len(true_labels)))\n",
    "    true_labels[flipped_idx] = 1 - true_labels[flipped_idx]\n",
    "    \n",
    "    # Train discriminator on real data\n",
    "    d_loss_true = discriminator.train_on_batch(images, true_labels)\n",
    "\n",
    "    # Prepare labels for generated data\n",
    "    gene_labels = np.ones((BATCH_SIZE, 1)) - np.random.uniform(low=0.0, high=0.1, size=(BATCH_SIZE, 1))\n",
    "    flipped_idx = np.random.choice(np.arange(len(gene_labels)), size=int(noise_prop*len(gene_labels)))\n",
    "    gene_labels[flipped_idx] = 1 - gene_labels[flipped_idx]\n",
    "    \n",
    "    # Train discriminator on generated data\n",
    "     d_loss_gene = discriminator.train_on_batch(generated_images, gene_labels)\n",
    "\n",
    "    d_loss = 0.5 * np.add(d_loss_true, d_loss_gene)\n",
    "    cum_d_loss += d_loss\n",
    "\n",
    "    # Train generator\n",
    "    noise_data = generate_noise(BATCH_SIZE, 100)\n",
    "    g_loss = gan.train_on_batch(noise_data, np.zeros((BATCH_SIZE, 1)))\n",
    "    cum_g_loss += g_loss\n",
    "\n",
    "  print('  Epoch: {}, Generator Loss: {}, Discriminator Loss: {}'.format(epoch+1, cum_g_loss/num_batches, cum_d_loss/num_batches))\n",
    "  show_imgs(\"epoch\" + str(epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "VbrnIMVREqsW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "LatestDCGAN.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
